{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\divya\\OneDrive\\Documents\\SEM4\\Capstone Project\\Capstone Project\\Data\\Processed\\Primary_Survey\\PrimaryData_fmt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Problem_Depression\n",
       "Sometimes        68\n",
       "Rarely           40\n",
       "Not at all       23\n",
       "Often            21\n",
       "Almost always     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the 'Problem_Depression' column to understand its distribution and how we can define the target variable\n",
    "df['Problem_Depression'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mental_Health_Issue\n",
       "1    0.598726\n",
       "0    0.401274\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable based on the 'Problem_Depression' column\n",
    "df['Mental_Health_Issue'] = df['Problem_Depression'].map({'Not at all': 0, 'Rarely': 0, 'Sometimes': 1, 'Often': 1, 'Almost always': 1})\n",
    "\n",
    "# Check the distribution of the new target variable\n",
    "target_distribution = df['Mental_Health_Issue'].value_counts(normalize=True)\n",
    "target_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Problem_Depression column contains responses categorized as \"Not at all\", \"Rarely\", \"Sometimes\", \"Often\", and \"Almost always\". Based on these responses, we can define the target variable for mental health issues as follows:\n",
    "\n",
    "0 (No Significant Mental Health Issue): Responses \"Not at all\" and \"Rarely\".\n",
    "1 (Potential Mental Health Issue): Responses \"Sometimes\", \"Often\", and \"Almost always\".\n",
    "\n",
    "\n",
    "The target variable Mental_Health_Issue has been successfully created, with approximately 60% of the instances indicating potential mental health issues (coded as 1) and 40% indicating no significant mental health issues (coded as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 95), (32, 95))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Selecting features for the model,\n",
    "feature_columns = ['Age', 'Gender', 'Current_Status', 'Problem_Interest', 'Problem_Sleep', \n",
    "                   'Problem_Energy', 'Problem_Appetite', 'Problem_Self_Doubt', 'Problem_Concentration', \n",
    "                   'Problem_Restlessness', 'Problem_Suicidal_Thoughts', 'Complete_Isolation', \n",
    "                   'Connection_Loss_Society', 'Friendship_Quality', 'Engagement_Group', \n",
    "                   'Prioritize_Well_Being', 'Current_Diet','Physical_Activity_Frequency','Sleep_Hours']\n",
    "\n",
    "# Define the features and the target\n",
    "X = df[feature_columns]\n",
    "y = df['Mental_Health_Issue']\n",
    "\n",
    "# Handling categorical variables and missing values\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the training and testing data\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_prepared.shape, X_test_prepared.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6875, 0.6666666666666666, 0.75, 0.7058823529411765)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the prepared training data\n",
    "dt_clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = dt_clf.predict(X_test_prepared)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.625,\n",
       "  'Precision': 0.5909090909090909,\n",
       "  'Recall': 0.8125,\n",
       "  'F1 Score': 0.6842105263157895},\n",
       " 'Random Forest': {'Accuracy': 0.71875,\n",
       "  'Precision': 0.6666666666666666,\n",
       "  'Recall': 0.875,\n",
       "  'F1 Score': 0.7567567567567568},\n",
       " 'Gradient Boosting': {'Accuracy': 0.6875,\n",
       "  'Precision': 0.65,\n",
       "  'Recall': 0.8125,\n",
       "  'F1 Score': 0.7222222222222222}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Dictionary to store models and their performance\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Random Forest\": rf_clf,\n",
    "    \"Gradient Boosting\": gb_clf\n",
    "}\n",
    "\n",
    "performance = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_prepared, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_prepared)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the metrics\n",
    "    performance[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "performance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
